{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e6ed0cd",
   "metadata": {},
   "source": [
    "# HDSC2022 Capstone Project\n",
    "## by Team Prophet\n",
    "\n",
    "The dataset contains information about the scholarship programs in China as of May 2019. <br>\n",
    "The data was collected through by scraping the [CUCAS website](https://www.cucas.edu.cn/china_scholarships/). <br>\n",
    "The code to the web scraping program and data cleaning program can be found [here](https://github.com/mcmuralishclint/CUCAS). <br>\n",
    "\n",
    "The goal of this project is to ... ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22f0b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "import optuna\n",
    "from optuna import Trial, visualization\n",
    "from optuna.samplers import TPESampler\n",
    "\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97b5221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to read the csv file using read_excel() function \n",
    "data = pd.read_excel('./data/china_scholarship.xls')  #might also need to pip install xlrd\n",
    "#data is our upgraded dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab288c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb041f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40395bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to rename the columns using the snake_case naming convention to improve readability\n",
    "data.columns = ['school_id', 'university', 'major', 'district', 'city', 'level', 'language', 'tuition_covered', 'accomodation_covered',\n",
    "'living_expense_covered', 'tuition_fees_to_pay', 'original_tuition_fee','start_month','start_year', 'accomodation_to_pay',\n",
    "'accomodation_duration', 'expense_to_pay', 'expense_duration']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78478dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us view an intuitive summary of our dataframe\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cac3111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let us see a preview of the data by looking at the first 5 rows \n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab243f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us also look at the last 5 rows of the dataframe\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93604211",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us see how many null values present in the columns \n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ea6e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us view the descriptive statistics of the dataframe. Note that this can only be applied to numerical values \n",
    "data[['tuition_covered', 'tuition_fees_to_pay', 'original_tuition_fee', 'accomodation_to_pay', 'expense_to_pay']].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5313d6b",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3341bcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = data[['original_tuition_fee', 'tuition_covered', 'tuition_fees_to_pay']]\n",
    "temp[\"check\"] = data['original_tuition_fee'] - data['tuition_covered']\n",
    "temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7780205f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print((temp['tuition_fees_to_pay'] != temp['check']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561d4b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp[temp['tuition_fees_to_pay'] != temp['check']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecbc51d",
   "metadata": {},
   "source": [
    "### Tuition to pay\n",
    "There are only 123 instances where the difference between orignal tuition and tuition covered is not equal to tuition to pay. <br> and this number 123 corresponds to the number of missing values  for both tuition covered and original tuition. <br>\n",
    "Based on the above, tuition to pay is not a good target for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7934e32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"accomodation_duration\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2fdb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = data.copy()\n",
    "\n",
    "#convert per year to per month\n",
    "#newdata['accomodation_to_pay'][newdata['accomodation_duration'] == \"YEAR\"] = newdata['accomodation_to_pay'][newdata['accomodation_duration'] == \"YEAR\"] / 12\n",
    "\n",
    "#convert per day to per year using 365 days per year\n",
    "newdata['accomodation_to_pay'][newdata['accomodation_duration'] == \"DAY\"] = newdata['accomodation_to_pay'][newdata['accomodation_duration'] == \"DAY\"] * 365\n",
    "\n",
    "#convert per term to per year using 3 terms in a year\n",
    "newdata['accomodation_to_pay'][newdata['accomodation_duration'] == \"TERM\"] = newdata['accomodation_to_pay'][newdata['accomodation_duration'] == \"TERM\"] * 2\n",
    "\n",
    "#convert per semester to per year using 2 semesters per year\n",
    "newdata['accomodation_to_pay'][newdata['accomodation_duration'] == \"SEMESTER\"] = newdata['accomodation_to_pay'][newdata['accomodation_duration'] == \"SEMESTER\"] * 2\n",
    "\n",
    "newdata.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e950b0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp2 = data[['living_expense_covered', 'expense_to_pay', \"expense_duration\"]]\n",
    "temp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35726c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"expense_duration\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd73fa5",
   "metadata": {},
   "source": [
    "### Accomodation to pay\n",
    "Accomodation to pay is always zero when accomodation is covered.\n",
    "\n",
    "### Expense to pay\n",
    "Expense to pay is zero when living expenses are covered. <br>\n",
    "Drop expense_duration as it is always per month, there's nothing to learn from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed5783",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create total expense to pay, sum of tuition to pay, accomodation to pay and expense to pay.\n",
    "newdata[\"total_expense\"] = newdata[[\"tuition_fees_to_pay\", \"accomodation_to_pay\", \"expense_to_pay\"]].sum(axis=1)\n",
    "newdata.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f70968",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab777987",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove redundant columns\n",
    "redund_cols = ['tuition_fees_to_pay', 'original_tuition_fee',\n",
    "               'accomodation_to_pay', 'tuition_covered',\n",
    "               'accomodation_duration', 'expense_to_pay', 'expense_duration',\n",
    "              \"school_id\", \"major\", \"city\"] #'tuition_covered', add/remove tuition covered to/from the features\n",
    "newdata = newdata.drop(columns=redund_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25bb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884f3522",
   "metadata": {},
   "source": [
    "### Inspect columns in new data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40468fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d63dd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata[\"district\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f4e091",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata[\"district\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8b2335",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata = newdata.replace(\"Licheng District\", \"Licheng\")\n",
    "newdata = newdata.replace(\"Xuhui District\", \"Xuhui\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7705210a",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata[\"district\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe20454",
   "metadata": {},
   "source": [
    "There are 38 unique disricts, we could predict total expense based on district."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bd0da06",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata[\"level\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da0b0de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata[\"university\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611a188",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata[\"language\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8127bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata[\"start_month\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc86f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "newdata[\"start_year\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22c8ca52",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47461268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us define the predictor columns and the target column \n",
    "# X is the predictor\n",
    "# y is the target variable\n",
    "X = newdata.drop(['total_expense'], axis = 1)\n",
    "y = newdata['total_expense']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78083900",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we are differentiating between the columns that are objects and the ones that are not\n",
    "obj_cols = list(X.select_dtypes(include = 'object').columns)\n",
    "num_cols = list(X.select_dtypes(exclude = 'object').columns)\n",
    "print(obj_cols)\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc40575",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430ad886",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split into train and validation\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                      test_size=0.3,\n",
    "                                                    random_state=42)\n",
    "\n",
    "print(f\"Train size: \\nxtrain: {X_train.shape}\\nytrain: {y_train.shape}\",\n",
    "      f\"\\n\\nTest size: \\nxtest: {X_test.shape}\\nytest: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acd2467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for numerical data\n",
    "#data is filled with the mean value\n",
    "#data is scaled with MinMaxScaler\n",
    "numerical_transformer = Pipeline(steps=[(\"impute\", SimpleImputer(strategy=\"mean\")), \n",
    "                                        ('scale', MinMaxScaler())])\n",
    "\n",
    "# Preprocessing for categorical data\n",
    "#data is encoded with OrdinalEncoder\n",
    "#data is scaled with MinMaxScaler\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('label_enc', OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=100)), ('scale', MinMaxScaler())])  \n",
    "#Changed to Ordinal Encoder to reduce dimensions\n",
    "\n",
    "# Bundle preprocessing for numerical and categorical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[('num', numerical_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, obj_cols)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c63c67c",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47f5f23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = RandomForestRegressor()\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "rf_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model) ])\n",
    "\n",
    "scores = cross_val_score(rf_clf, X_train, y_train, cv=5,\n",
    "                        scoring='neg_mean_absolute_error')\n",
    "print(\"MAE scores:\\n\", scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece60dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf.fit(X_train, y_train)\n",
    "rf_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fedb2e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_score(params):\n",
    "    model = RandomForestRegressor(n_jobs=-1, **params)\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)])\n",
    "    mae = -1 * cross_val_score(pipe, X_train, y_train, cv=5,\n",
    "                        scoring='neg_mean_absolute_error').mean()\n",
    "    return mae\n",
    "\n",
    "\n",
    "def rf_objective(trial):\n",
    "    params = {\n",
    "                \"criterion\" : trial.suggest_categorical(\"criterion\", [\"mse\", \"mae\"]),\n",
    "                \"n_estimators\" : trial.suggest_int('n_estimators', 1, 1000),\n",
    "                'max_depth':trial.suggest_int('max_depth', 1, 7),\n",
    "             }\n",
    "    return(rf_score(params))\n",
    "\n",
    "\n",
    "def print_best_callback(study, trial):\n",
    "    print(f\"Best value: {study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb3177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(0)\n",
    "rf_study = optuna.create_study(direction='minimize',sampler=TPESampler())\n",
    "rf_study.optimize(rf_objective, n_trials= 20, show_progress_bar = True, callbacks=[print_best_callback])\n",
    "rf_best = rf_study.best_params\n",
    "rf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3186020",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned model\n",
    "rf_model = RandomForestRegressor(**rf_best)\n",
    "\n",
    "#retrain with full data\n",
    "rf_tuned_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', rf_model)])\n",
    "rf_tuned_clf.fit(X_train, y_train)\n",
    "rf_tuned_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd32ab2a",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320b9d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = XGBRegressor()\n",
    "\n",
    "# Bundle preprocessing and modeling code in a pipeline\n",
    "xg_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model) ])\n",
    "\n",
    "scores = cross_val_score(xg_clf, X_train, y_train,\n",
    "                              cv=5,\n",
    "                              scoring='neg_mean_absolute_error')\n",
    "print(\"MAE scores:\\n\", scores)\n",
    "print(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b1eab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "xg_clf.fit(X_train, y_train)\n",
    "xg_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d296b4",
   "metadata": {},
   "source": [
    "### Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555ae45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def xg_score(params):\n",
    "    model = XGBRegressor( **params)\n",
    "    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', model)])\n",
    "    mae = -1 * cross_val_score(pipe, X_train, y_train, cv=5,\n",
    "                        scoring='neg_mean_absolute_error').mean()\n",
    "    return mae\n",
    "\n",
    "\n",
    "def xg_objective(trial):\n",
    "    params = {\n",
    "                \"n_estimators\" : trial.suggest_int('n_estimators', 0, 500),\n",
    "                'max_depth':trial.suggest_int('max_depth', 3, 5),\n",
    "                'reg_alpha':trial.suggest_uniform('reg_alpha',0,6),\n",
    "                'reg_lambda':trial.suggest_uniform('reg_lambda',0,2),\n",
    "                'min_child_weight':trial.suggest_int('min_child_weight',0,5),\n",
    "                'gamma':trial.suggest_uniform('gamma', 0, 4),\n",
    "                'learning_rate':trial.suggest_loguniform('learning_rate',0.05,0.5),\n",
    "                'colsample_bytree':trial.suggest_uniform('colsample_bytree',0.4,0.9),\n",
    "                'subsample':trial.suggest_uniform('subsample',0.4,0.9),\n",
    "                'nthread' : -1\n",
    "            }\n",
    "    return(xg_score(params))\n",
    "\n",
    "\n",
    "def print_best_callback(study, trial):\n",
    "    print(f\"Best value: {study.best_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7943816",
   "metadata": {},
   "outputs": [],
   "source": [
    "optuna.logging.set_verbosity(0)\n",
    "xg_study = optuna.create_study(direction='minimize',sampler=TPESampler())\n",
    "xg_study.optimize(xg_objective, n_trials= 50, show_progress_bar = True, callbacks=[print_best_callback])\n",
    "xg_best = xg_study.best_params\n",
    "xg_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab636c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tuned model\n",
    "xg_model = XGBRegressor(**xg_best)\n",
    "\n",
    "#retrain with full data\n",
    "xg_tuned_clf = Pipeline(steps=[('preprocessor', preprocessor),\n",
    "                      ('model', xg_model)])\n",
    "xg_tuned_clf.fit(X_train, y_train)\n",
    "xg_tuned_clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5149a2",
   "metadata": {},
   "source": [
    "## Results Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7633e971",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_results(actual, pred):\n",
    "    rsquared = r2_score(actual, pred)\n",
    "    mae = mean_absolute_error(actual, pred)\n",
    "    rmse = mean_squared_error(actual, pred, squared=False)\n",
    "    return pd.DataFrame([rsquared, mae, rmse], index=[\"$R^2$\", \"MAE\", \"RMSE\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe4d15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RF\n",
    "rf_base_pred = rf_clf.predict(X_test)\n",
    "rf_tuned_pred = rf_tuned_clf.predict(X_test)\n",
    "\n",
    "#XG\n",
    "xg_base_pred = xg_clf.predict(X_test)\n",
    "xg_tuned_pred = xg_tuned_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a7b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame()\n",
    "temp[\"rf_base\"] = show_results(y_test, rf_base_pred)\n",
    "temp[\"rf_tuned\"] = show_results(y_test, rf_tuned_pred)\n",
    "temp[\"xg_base\"] = show_results(y_test, xg_base_pred)\n",
    "temp[\"xg_tuned\"] = show_results(y_test, xg_tuned_pred)\n",
    "temp.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85fbc349",
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare predictions to actual data\n",
    "temp = pd.DataFrame()\n",
    "temp[\"b_rf_pred\"] = rf_clf.predict(X_test)\n",
    "temp[\"b_xg_pred\"] = xg_clf.predict(X_test)\n",
    "temp[\"actual\"] = y_test.values\n",
    "temp[\"rf_pred\"] = rf_tuned_clf.predict(X_test)\n",
    "temp[\"xg_pred\"] = xg_tuned_clf.predict(X_test)\n",
    "temp.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e71fd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526f430f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
